---
title: "TRGN_510_final"
author: "bo"
date: "11/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### load librarier we need
```{r}
library(MLSeq)
library(DESeq2)
```
### Create a new function to put each htseqcounts data as a df
```{r}
predata <- function(val) {
  df = myfilelist[val]
  df <- as.data.frame(df)
  df <- data.frame(df[,-1], row.names = df[,1])
  colnames(df) <- myfilename[val]
  print(df)
}
```
## Prepare the input data
### First we put all stage_i datasets
```{r}
mypath <- "./training_data/stage_i_htseqdata/"
myfilepath <- list.files("./training_data/stage_i_htseqdata/", pattern = "htseq", full.names = TRUE)
myfilename <- list.files(mypath, pattern = "htseq")
```
### Use lapply to make a list of our data
```{r}
myfilelist <- lapply(myfilepath, read.table)
```
### use for loop to merge datasets
```{r}
p <- predata(1)
library(dplyr)
for (i in 2:20){
  p=merge(p,predata(i),by = 0, all = T)
  p <- data.frame(p[,-1], row.names = p[,1])
}
```
### Second we put all stage_iia datasets
```{r}
mypath <- "training_data/stage_iia_htseqdata/"
myfilepath <- list.files(mypath,pattern = "htseq", full.names = TRUE)
myfilename <- list.files(mypath, pattern = "htseq")
myfilelist <- lapply(myfilepath, read.table)
q <- predata(1)
library(dplyr)
for (i in 2:20){
  q=merge(q,predata(i),by = 0, all = T)
  q <- data.frame(q[,-1], row.names = q[,1])
}
```
### Then we merge the two stage df together
```{r}
df_all=merge(p,q,by=0,all=T)
df_all <- data.frame(df_all[,-1], row.names = df_all[,1])
df_all_1 <- df_all_1[-1,]
df <- df_all_1
```
## Find the significant genes
### we create class of the our df_all(the first 20 datasets are stage i data)
```{r}
class <- data.frame(condition = factor(rep(c("i","iia"),c(20,20))))
class
```
### DESeq2, using DESeq2 to create input data of training and testing
```{r}
set.seed(2128)
vars <- sort(apply(df, 1, var, na.rm = TRUE), decreasing = TRUE)
data <- df[names(vars)[1:100],]
nTest <- ceiling(ncol(data) * 0.3)
ind <- sample(ncol(data),nTest,FALSE)
```
### Minimum count is set to 1 
```{r}
data.train <- as.matrix(data[ ,-ind] + 1)
data.test <- as.matrix(data[ ,ind] + 1)
classtr <- DataFrame(condition = class[-ind, ])
classts <- DataFrame(condition = class[ind, ])
```
### Now we have the traning and test sets
```{r}
data.trainS4 = DESeqDataSetFromMatrix(countData = data.train, colData = classtr,
design = formula(~condition))
data.testS4 = DESeqDataSetFromMatrix(countData = data.test, colData = classts,
design = formula(~condition))
```
### Using availableMethods to see what models we have.
```{r}
availableMethods()
```
## Normalization and training the model in MLSeq
### Normalize data using deseq-vst and train dataset with method "svmRadial"
```{r}
set.seed(2128)
fit.svm <- classify(data = data.trainS4, method = "svmRadial",
preProcessing = "deseq-vst", ref = "iia", tuneLength = 10,
control = trainControl(method = "repeatedcv", number = 5,
repeats = 10, classProbs = TRUE))
show(fit.svm)
```
```{r}
trained(fit.svm)
```
### plot the tuning parameters on the model
```{r}
plot(fit.svm)
```
### Defining the control list for selected classifier, so we define all the method MLSeq provided.
```{r}
ctrl.svm <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
ctrl.plda <- discreteControl(method = "repeatedcv", number = 5, repeats = 1,
tuneLength = 10)
ctrl.voomDLDA <- voomControl(method = "repeatedcv", number = 5, repeats = 1,
tuneLength = 10)
```
### svm model
```{r}
fit.svm <- classify(data = data.trainS4, method = "svmRadial",
preProcessing = "deseq-vst", ref = "iia", tuneLength = 10,
control = ctrl.svm)
fit.svm_trained <-trained(fit.svm)
fit.svm_trained
plot(fit.svm_trained)
```
### PLDA model
```{r}
fit.plda <- classify(data = data.trainS4, method = "PLDA", normalize = "deseq",
ref = "iia", control = ctrl.plda)
fit.plda_trained <- trained(fit.plda)
fit.plda_trained
```
### Then we test the model with test data we've built.
```{r}
pred.svm <- predict(fit.svm, data.testS4)
pred.svm
```
```{r}
pred.svm <- relevel(pred.svm, ref = "iia")
actual <- relevel(classts$condition, ref = "iia")
tbl <- table(Predicted = pred.svm, Actual = actual)
confusionMatrix(tbl, positive = "iia")
```
## Comparing the performance of classifiers
```{r}
set.seed(2128)
ctrl.continuous <- trainControl(method = "repeatedcv", number = 5, repeats = 10)
ctrl.discrete <- discreteControl(method = "repeatedcv", number = 5, repeats = 10,tuneLength = 10)
ctrl.voom <- voomControl(method = "repeatedcv",number = 5, repeats = 10,
tuneLength = 10)
```

```{r}
fit.svm <- classify(data = data.trainS4, method = "svmRadial",
preProcessing = "deseq-vst", ref = "i", tuneLength = 10,
control = ctrl.continuous)
fit.NSC <- classify(data = data.trainS4, method = "pam",
preProcessing = "deseq-vst", ref = "i", tuneLength = 10,
control = ctrl.continuous)
```
```{r}
fit.plda <- classify(data = data.trainS4, method = "PLDA", normalize = "deseq",
ref = "i", control = ctrl.discrete)
fit.plda2 <- classify(data = data.trainS4, method = "PLDA2", normalize = "deseq",
ref = "i", control = ctrl.discrete)
fit.nblda <- classify(data = data.trainS4, method = "NBLDA", normalize = "deseq",
ref = "i", control = ctrl.discrete)
```


```{r}
fit.voomNSC <- classify(data = data.trainS4, method = "voomNSC",
normalize = "deseq", ref = "iia", control = ctrl.voom)
fit.voomNSC
```

```{r}
pred.svm <- predict(fit.svm, data.testS4)
pred.NSC <- predict(fit.NSC, data.testS4)
```

```{r}
pred.svm
pred.NSC
```
### Determining possible biomarkers using sparse classifiers
```{r}
selectedGenes(fit.voomNSC)
```
## Updating an MLSeq object using update
```{r}
set.seed(2128)
ctrl <- discreteControl(method = "repeatedcv", number = 5, repeats = 2,
tuneLength = 10)
# PLDA without power transformation
fit <- classify(data = data.trainS4, method = "PLDA", normalize = "deseq",
ref = "i", control = ctrl)
show(fit)
```
```{r}
method(fit) <- "PLDA2"
show(fit)
```
```{r}
ref(fit) <- "i"
normalization(fit) <- "TMM"
metaData(fit)
```
```{r}
fit <-update(fit)
```

```{r}
show(fit)
```
```{r}
dld1 = MLearn( mol.biol~., data.trainS4, 1:28)
```

